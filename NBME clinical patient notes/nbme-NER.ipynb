{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29a6767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:25.384427Z",
     "iopub.status.busy": "2022-12-29T21:08:25.383596Z",
     "iopub.status.idle": "2022-12-29T21:08:28.386811Z",
     "shell.execute_reply": "2022-12-29T21:08:28.385865Z"
    },
    "papermill": {
     "duration": 3.028846,
     "end_time": "2022-12-29T21:08:28.389345",
     "exception": false,
     "start_time": "2022-12-29T21:08:25.360499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import  LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import ast\n",
    "import os\n",
    "import dill\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoConfig,AutoModel\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from ast import literal_eval\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914a0038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:28.416215Z",
     "iopub.status.busy": "2022-12-29T21:08:28.415768Z",
     "iopub.status.idle": "2022-12-29T21:08:28.426624Z",
     "shell.execute_reply": "2022-12-29T21:08:28.425610Z"
    },
    "papermill": {
     "duration": 0.029298,
     "end_time": "2022-12-29T21:08:28.429414",
     "exception": false,
     "start_time": "2022-12-29T21:08:28.400116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb2b8655cd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0407278a",
   "metadata": {
    "papermill": {
     "duration": 0.010327,
     "end_time": "2022-12-29T21:08:28.450146",
     "exception": false,
     "start_time": "2022-12-29T21:08:28.439819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load dataframes\n",
    "\n",
    "##### Let's load all the datasets from the competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae7b113c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:28.472692Z",
     "iopub.status.busy": "2022-12-29T21:08:28.472422Z",
     "iopub.status.idle": "2022-12-29T21:08:28.476554Z",
     "shell.execute_reply": "2022-12-29T21:08:28.475567Z"
    },
    "papermill": {
     "duration": 0.018243,
     "end_time": "2022-12-29T21:08:28.478820",
     "exception": false,
     "start_time": "2022-12-29T21:08:28.460577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR = '/kaggle/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdceb12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:28.500790Z",
     "iopub.status.busy": "2022-12-29T21:08:28.500536Z",
     "iopub.status.idle": "2022-12-29T21:08:29.245332Z",
     "shell.execute_reply": "2022-12-29T21:08:29.244386Z"
    },
    "papermill": {
     "duration": 0.758404,
     "end_time": "2022-12-29T21:08:29.247733",
     "exception": false,
     "start_time": "2022-12-29T21:08:28.489329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv(DIR+\"nbme-score-clinical-patient-notes/features.csv\")\n",
    "patient_notes = pd.read_csv(DIR+\"nbme-score-clinical-patient-notes/patient_notes.csv\")\n",
    "test = pd.read_csv(DIR+\"nbme-score-clinical-patient-notes/test.csv\")\n",
    "train= pd.read_csv(DIR+\"nbme-score-clinical-patient-notes/train.csv\")\n",
    "sample_submission= pd.read_csv(DIR+\"nbme-score-clinical-patient-notes/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a805991",
   "metadata": {
    "papermill": {
     "duration": 0.010439,
     "end_time": "2022-12-29T21:08:29.269107",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.258668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "##### The features.csv file contain all the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e379725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.291262Z",
     "iopub.status.busy": "2022-12-29T21:08:29.290949Z",
     "iopub.status.idle": "2022-12-29T21:08:29.306155Z",
     "shell.execute_reply": "2022-12-29T21:08:29.305343Z"
    },
    "papermill": {
     "duration": 0.028457,
     "end_time": "2022-12-29T21:08:29.307968",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.279511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Chest-pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Lightheaded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_num  case_num                                       feature_text\n",
       "0            0         0  Family-history-of-MI-OR-Family-history-of-myoc...\n",
       "1            1         0                 Family-history-of-thyroid-disorder\n",
       "2            2         0                                     Chest-pressure\n",
       "3            3         0                              Intermittent-symptoms\n",
       "4            4         0                                        Lightheaded"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db3d35",
   "metadata": {
    "papermill": {
     "duration": 0.010686,
     "end_time": "2022-12-29T21:08:29.329444",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.318758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### The patient_notes.csv fie contains all the patient history notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c996a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.353051Z",
     "iopub.status.busy": "2022-12-29T21:08:29.351541Z",
     "iopub.status.idle": "2022-12-29T21:08:29.362492Z",
     "shell.execute_reply": "2022-12-29T21:08:29.361699Z"
    },
    "papermill": {
     "duration": 0.024276,
     "end_time": "2022-12-29T21:08:29.364382",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.340106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17-year-old male, has come to the student heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Dillon Cleveland is a 17 y.o. male patient wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>a 17 yo m c/o palpitation started 3 mos ago; \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17yo male with no pmh here for evaluation of p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pn_num  case_num                                         pn_history\n",
       "0       0         0  17-year-old male, has come to the student heal...\n",
       "1       1         0  17 yo male with recurrent palpitations for the...\n",
       "2       2         0  Dillon Cleveland is a 17 y.o. male patient wit...\n",
       "3       3         0  a 17 yo m c/o palpitation started 3 mos ago; \\...\n",
       "4       4         0  17yo male with no pmh here for evaluation of p..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_notes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db15f1",
   "metadata": {
    "papermill": {
     "duration": 0.010413,
     "end_time": "2022-12-29T21:08:29.385486",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.375073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " As we can see the training set contains the annotation feature that is comprised of strings of medical features detected in the patient history and the corresponding location that is the target feature that our model aims to detect. The id feature is simply the result of concatenating the case_num, pn_num and feature_num features values toghether. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21258a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.408423Z",
     "iopub.status.busy": "2022-12-29T21:08:29.407761Z",
     "iopub.status.idle": "2022-12-29T21:08:29.417949Z",
     "shell.execute_reply": "2022-12-29T21:08:29.417101Z"
    },
    "papermill": {
     "duration": 0.023574,
     "end_time": "2022-12-29T21:08:29.419876",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.396302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>['dad with recent heart attcak']</td>\n",
       "      <td>['696 724']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>['mom with \"thyroid disease']</td>\n",
       "      <td>['668 693']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>['chest pressure']</td>\n",
       "      <td>['203 217']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>['intermittent episodes', 'episode']</td>\n",
       "      <td>['70 91', '176 183']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>['felt as if he were going to pass out']</td>\n",
       "      <td>['222 258']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                                 annotation              location  \n",
       "0          ['dad with recent heart attcak']           ['696 724']  \n",
       "1             ['mom with \"thyroid disease']           ['668 693']  \n",
       "2                        ['chest pressure']           ['203 217']  \n",
       "3      ['intermittent episodes', 'episode']  ['70 91', '176 183']  \n",
       "4  ['felt as if he were going to pass out']           ['222 258']  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7110bcb",
   "metadata": {
    "papermill": {
     "duration": 0.011114,
     "end_time": "2022-12-29T21:08:29.442048",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.430934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The test.csv dataset contains only information about the case number, the patient number and the feature number. The feature number will have to be identified in the corresponding text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a56640d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.466199Z",
     "iopub.status.busy": "2022-12-29T21:08:29.465349Z",
     "iopub.status.idle": "2022-12-29T21:08:29.474991Z",
     "shell.execute_reply": "2022-12-29T21:08:29.473842Z"
    },
    "papermill": {
     "duration": 0.024778,
     "end_time": "2022-12-29T21:08:29.477726",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.452948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num\n",
       "0  00016_000         0      16            0\n",
       "1  00016_001         0      16            1\n",
       "2  00016_002         0      16            2\n",
       "3  00016_003         0      16            3\n",
       "4  00016_004         0      16            4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d8f1b",
   "metadata": {
    "papermill": {
     "duration": 0.011109,
     "end_time": "2022-12-29T21:08:29.500106",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.488997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### This is an example of the format of the submission on Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423828c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.525164Z",
     "iopub.status.busy": "2022-12-29T21:08:29.524867Z",
     "iopub.status.idle": "2022-12-29T21:08:29.533533Z",
     "shell.execute_reply": "2022-12-29T21:08:29.532537Z"
    },
    "papermill": {
     "duration": 0.023839,
     "end_time": "2022-12-29T21:08:29.535520",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.511681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>200 250;300 400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>75 110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         location\n",
       "0  00016_000            0 100\n",
       "1  00016_001              NaN\n",
       "2  00016_002  200 250;300 400\n",
       "3  00016_003              NaN\n",
       "4  00016_004           75 110"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6dfdb8",
   "metadata": {
    "papermill": {
     "duration": 0.010826,
     "end_time": "2022-12-29T21:08:29.557914",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.547088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Merging the train and test datasets with the patient notes and features datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe97643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.582771Z",
     "iopub.status.busy": "2022-12-29T21:08:29.581888Z",
     "iopub.status.idle": "2022-12-29T21:08:29.631922Z",
     "shell.execute_reply": "2022-12-29T21:08:29.630975Z"
    },
    "papermill": {
     "duration": 0.064605,
     "end_time": "2022-12-29T21:08:29.634342",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.569737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.merge(patient_notes,on=['case_num','pn_num']).merge(features,on=['case_num','feature_num'])\n",
    "test = test.merge(patient_notes,on=['case_num','pn_num']).merge(features,on=['case_num','feature_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92eb87b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.662259Z",
     "iopub.status.busy": "2022-12-29T21:08:29.661910Z",
     "iopub.status.idle": "2022-12-29T21:08:29.676373Z",
     "shell.execute_reply": "2022-12-29T21:08:29.675242Z"
    },
    "papermill": {
     "duration": 0.031555,
     "end_time": "2022-12-29T21:08:29.679086",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.647531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>['dad with recent heart attcak']</td>\n",
       "      <td>['696 724']</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00041_000</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00046_000</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>['father: heart attack']</td>\n",
       "      <td>['824 844']</td>\n",
       "      <td>Mr. Cleveland is a 17yo M who was consented by...</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00082_000</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>['Father MI']</td>\n",
       "      <td>['622 631']</td>\n",
       "      <td>17 yo M w/ no cardiac or arrhythmia PMH presen...</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00100_000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>['Dad-MI']</td>\n",
       "      <td>['735 741']</td>\n",
       "      <td>HPI: Dillon Cleveland is an otherwise healthy ...</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num                        annotation  \\\n",
       "0  00016_000         0      16            0  ['dad with recent heart attcak']   \n",
       "1  00041_000         0      41            0                                []   \n",
       "2  00046_000         0      46            0          ['father: heart attack']   \n",
       "3  00082_000         0      82            0                     ['Father MI']   \n",
       "4  00100_000         0     100            0                        ['Dad-MI']   \n",
       "\n",
       "      location                                         pn_history  \\\n",
       "0  ['696 724']  HPI: 17yo M presents with palpitations. Patien...   \n",
       "1           []  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...   \n",
       "2  ['824 844']  Mr. Cleveland is a 17yo M who was consented by...   \n",
       "3  ['622 631']  17 yo M w/ no cardiac or arrhythmia PMH presen...   \n",
       "4  ['735 741']  HPI: Dillon Cleveland is an otherwise healthy ...   \n",
       "\n",
       "                                        feature_text  \n",
       "0  Family-history-of-MI-OR-Family-history-of-myoc...  \n",
       "1  Family-history-of-MI-OR-Family-history-of-myoc...  \n",
       "2  Family-history-of-MI-OR-Family-history-of-myoc...  \n",
       "3  Family-history-of-MI-OR-Family-history-of-myoc...  \n",
       "4  Family-history-of-MI-OR-Family-history-of-myoc...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "676dade8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.706703Z",
     "iopub.status.busy": "2022-12-29T21:08:29.706406Z",
     "iopub.status.idle": "2022-12-29T21:08:29.719009Z",
     "shell.execute_reply": "2022-12-29T21:08:29.718161Z"
    },
    "papermill": {
     "duration": 0.028461,
     "end_time": "2022-12-29T21:08:29.721044",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.692583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>Chest-pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>Lightheaded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                                          pn_history  \\\n",
       "0  HPI: 17yo M presents with palpitations. Patien...   \n",
       "1  HPI: 17yo M presents with palpitations. Patien...   \n",
       "2  HPI: 17yo M presents with palpitations. Patien...   \n",
       "3  HPI: 17yo M presents with palpitations. Patien...   \n",
       "4  HPI: 17yo M presents with palpitations. Patien...   \n",
       "\n",
       "                                        feature_text  \n",
       "0  Family-history-of-MI-OR-Family-history-of-myoc...  \n",
       "1                 Family-history-of-thyroid-disorder  \n",
       "2                                     Chest-pressure  \n",
       "3                              Intermittent-symptoms  \n",
       "4                                        Lightheaded  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adafc87",
   "metadata": {
    "papermill": {
     "duration": 0.012732,
     "end_time": "2022-12-29T21:08:29.746366",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.733634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb0f5b",
   "metadata": {
    "papermill": {
     "duration": 0.012269,
     "end_time": "2022-12-29T21:08:29.771044",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.758775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### For the choice of the epochs, lr and batch size we followed the guidance of the BERT paper and tried the following combinations: \n",
    "-  ##### Batch size: 16, 32\n",
    "-  ##### Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
    "-  ##### Number of epochs: 2, 3, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c362d",
   "metadata": {
    "papermill": {
     "duration": 0.011993,
     "end_time": "2022-12-29T21:08:29.795500",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.783507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The rules of the competition do not consent to use the internet when doing the final submission. Thus, when this code runs on Kaggle the BERT model is taken from a dataset on Kaggle in which it was loaded and so the model_name in the hyperparameters is set to: '../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased'. \n",
    "Otherwise, when internet can be used the model_name is simply 'bert-base-uncased'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d925d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.820955Z",
     "iopub.status.busy": "2022-12-29T21:08:29.820679Z",
     "iopub.status.idle": "2022-12-29T21:08:29.825999Z",
     "shell.execute_reply": "2022-12-29T21:08:29.825034Z"
    },
    "papermill": {
     "duration": 0.020497,
     "end_time": "2022-12-29T21:08:29.828228",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.807731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'max_length': 512,\n",
    "    'padding': 'max_length',\n",
    "    'return_offsets_mapping': True,\n",
    "    'truncation': 'only_second',\n",
    "    'model_name': '../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased',\n",
    "    'dropout': 0.1,\n",
    "    'lr': [5e-5, 3e-5, 2e-5],\n",
    "    'val_size': 0.2,\n",
    "    'seed': 999,\n",
    "    'batch_size': [16,32],\n",
    "    'epochs': [2,3,4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffd587f",
   "metadata": {
    "papermill": {
     "duration": 0.011713,
     "end_time": "2022-12-29T21:08:29.851549",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.839836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19df2c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.876476Z",
     "iopub.status.busy": "2022-12-29T21:08:29.876227Z",
     "iopub.status.idle": "2022-12-29T21:08:29.880480Z",
     "shell.execute_reply": "2022-12-29T21:08:29.879447Z"
    },
    "papermill": {
     "duration": 0.019205,
     "end_time": "2022-12-29T21:08:29.882858",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.863653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = DIR + 'nbmemodel'\n",
    "DATA_EXISTS = os.path.exists(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c173b2df",
   "metadata": {
    "papermill": {
     "duration": 0.011672,
     "end_time": "2022-12-29T21:08:29.906823",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.895151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I fine-tuned the bert-base-uncased model. The Bert model requires a certain input format so we first use the Bert tokenizer to achieve that trough the AutoTokenizer class. By quoting the Hugging Face tutorial, \"AutoClasses are here so that you automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary, that will directly create a class of the relevant architecture\".. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89128ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:29.933918Z",
     "iopub.status.busy": "2022-12-29T21:08:29.933669Z",
     "iopub.status.idle": "2022-12-29T21:08:30.012503Z",
     "shell.execute_reply": "2022-12-29T21:08:30.011429Z"
    },
    "papermill": {
     "duration": 0.096446,
     "end_time": "2022-12-29T21:08:30.014797",
     "exception": false,
     "start_time": "2022-12-29T21:08:29.918351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DATA_EXISTS:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(DATA_PATH+\"/my_tokenizer/\",normalization=True)\n",
    "    config = AutoConfig.from_pretrained(DATA_PATH+\"/my_tokenizer/config.json\")\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(hyperparameters['model_name'],normalization=True) \n",
    "    config = AutoConfig.from_pretrained(hyperparameters['model_name'])\n",
    "    tokenizer.save_pretrained('/my_tokenizer')\n",
    "    config.save_pretrained('/my_tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1992d8",
   "metadata": {
    "papermill": {
     "duration": 0.012097,
     "end_time": "2022-12-29T21:08:30.038972",
     "exception": false,
     "start_time": "2022-12-29T21:08:30.026875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0062a69",
   "metadata": {
    "papermill": {
     "duration": 0.011491,
     "end_time": "2022-12-29T21:08:30.062241",
     "exception": false,
     "start_time": "2022-12-29T21:08:30.050750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### There are 144 unique classes, i.e. unique medical features. As we can see however the numbers are not ordered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19e6ae16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:30.087472Z",
     "iopub.status.busy": "2022-12-29T21:08:30.086642Z",
     "iopub.status.idle": "2022-12-29T21:08:30.094663Z",
     "shell.execute_reply": "2022-12-29T21:08:30.093072Z"
    },
    "papermill": {
     "duration": 0.023222,
     "end_time": "2022-12-29T21:08:30.097200",
     "exception": false,
     "start_time": "2022-12-29T21:08:30.073978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes:  [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 700, 701, 702, 703, 704, 705, 706, 707, 708, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916]\n",
      "\n",
      "Number of unique classes:  144\n"
     ]
    }
   ],
   "source": [
    "EMPTY =  -1\n",
    "CLASSES = [EMPTY,]+features.feature_num.unique().tolist()\n",
    "print(\"Unique classes: \", CLASSES)\n",
    "print(\"\\nNumber of unique classes: \", len(CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da8e1b",
   "metadata": {
    "papermill": {
     "duration": 0.011485,
     "end_time": "2022-12-29T21:08:30.120767",
     "exception": false,
     "start_time": "2022-12-29T21:08:30.109282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Each feature number is encoded into unique labels that go from 1 to 143 plus the label 0 that signals the \"empty feature\". This will be used when the patient_history text will be tokenized and the scope of the model will be to classify each token, if the label is 0 it means that the corresponding token is not part of any medical feature while if the label is a number between 1-143 that token is a part of the medical feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ee73885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:30.145555Z",
     "iopub.status.busy": "2022-12-29T21:08:30.144800Z",
     "iopub.status.idle": "2022-12-29T21:08:30.163111Z",
     "shell.execute_reply": "2022-12-29T21:08:30.162061Z"
    },
    "papermill": {
     "duration": 0.033588,
     "end_time": "2022-12-29T21:08:30.165908",
     "exception": false,
     "start_time": "2022-12-29T21:08:30.132320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.1.3 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "if DATA_EXISTS:\n",
    "    label_encoder = dill.load(open(DATA_PATH+\"/label_encoder.dill\",'rb'))\n",
    "else:\n",
    "    # label_encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    # Encode labels\n",
    "    label_encoder.fit(CLASSES)\n",
    "    dill.dump(label_encoder,open('label_encoder.dill','wb'))\n",
    "    \n",
    "train['TARGET']= label_encoder.transform(train['feature_num'])\n",
    "test['TARGET']= label_encoder.transform(test['feature_num'])\n",
    "N_CLASSES = len(label_encoder.classes_)\n",
    "EMPTY_IDX = label_encoder.transform([EMPTY,])[0]\n",
    "print(f\"Empty label: {EMPTY_IDX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc2eb62",
   "metadata": {
    "papermill": {
     "duration": 0.011673,
     "end_time": "2022-12-29T21:08:30.190325",
     "exception": false,
     "start_time": "2022-12-29T21:08:30.178652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ausiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd32287f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:30.215417Z",
     "iopub.status.busy": "2022-12-29T21:08:30.215137Z",
     "iopub.status.idle": "2022-12-29T21:08:30.229459Z",
     "shell.execute_reply": "2022-12-29T21:08:30.228654Z"
    },
    "papermill": {
     "duration": 0.029082,
     "end_time": "2022-12-29T21:08:30.231253",
     "exception": false,
     "start_time": "2022-12-29T21:08:30.202171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_location(locations):\n",
    "    \"\"\"This function transform the location features from a string representation of a list to a list of tuples\"\"\"\n",
    "    for x in [\"[\",\"]\",\"'\"]:\n",
    "        locations = locations.replace(x,'')\n",
    "    locations = locations.replace(',',';')\n",
    "    locations = locations.split(\";\")\n",
    "    res = []\n",
    "    for location in locations:\n",
    "        if location:\n",
    "            x,y = location.split()\n",
    "            res.append((int(x),int(y)))\n",
    "    return sorted(res,key=lambda x:x[0])\n",
    "\n",
    "def decode_metrics(locations):\n",
    "    res = []\n",
    "    for location in ast.literal_eval(locations):\n",
    "        if location:\n",
    "            for loc in location.split(';'):\n",
    "                x,y = loc.split()\n",
    "                res.append(np.arange(int(x), int(y)))\n",
    "    res = np.array(res, dtype = object)\n",
    "    try:\n",
    "        res = np.concatenate(res)\n",
    "        res = np.array(list(set(res)))\n",
    "    except:\n",
    "        pass\n",
    "    return res\n",
    "\n",
    "def decode_position(pos):\n",
    "    \"\"\"This function transforms the predicted position to the format required in the Kaggle submission \"\"\"\n",
    "    return \";\".join([\" \".join(np.array(p).astype(str)) for p in pos])\n",
    "\n",
    "\n",
    "def translate(preds,targets_to_row_ids,offsets):\n",
    "    \"\"\"This function takes the predicitons and for each target feature in the test dataset \n",
    "    checks whether that feature is predicted somewhere in the sequence.\n",
    "    If a target feature is detected in the prediction vector, it returns the characters positions of the feature.\"\"\"\n",
    "    all_ids = []\n",
    "    all_pos = []\n",
    "\n",
    "    for k in range(len(preds)):\n",
    "        offset = offsets[k]\n",
    "        pred = preds[k]\n",
    "        \n",
    "        targets_to_ids = targets_to_row_ids[k]\n",
    "        prediction = {targets_to_ids[t]:[] for t in targets_to_ids}\n",
    "        i = 0\n",
    "        while i<hyperparameters['max_length']:\n",
    "            label = pred[i]\n",
    "        \n",
    "            if label == EMPTY_IDX:\n",
    "                i += 1\n",
    "                continue\n",
    "            if label in targets_to_ids:\n",
    "                key = targets_to_ids[label]\n",
    "                start = offset[i][0]\n",
    "                while i<hyperparameters['max_length']:\n",
    "                    if pred[i] != label:\n",
    "                        break\n",
    "                    else:\n",
    "                        end = max(offset[i])\n",
    "                    i += 1\n",
    "                if  end == 0:\n",
    "                    break\n",
    "                prediction[key].append((start,end))\n",
    "            else:\n",
    "                i+=1\n",
    "        for key in prediction:\n",
    "            all_ids.append(key)\n",
    "            all_pos.append(decode_position(prediction[key]))\n",
    "    df = pd.DataFrame({\n",
    "        \"id\":all_ids,\n",
    "        \"location\": all_pos\n",
    "    })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da623b01",
   "metadata": {
    "papermill": {
     "duration": 0.011458,
     "end_time": "2022-12-29T21:08:30.254450",
     "exception": false,
     "start_time": "2022-12-29T21:08:30.242992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing the inputs for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e52fe",
   "metadata": {
    "papermill": {
     "duration": 0.01238,
     "end_time": "2022-12-29T21:08:30.278467",
     "exception": false,
     "start_time": "2022-12-29T21:08:30.266087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the following cell we use the encode_plus function from the Hugging Face transformers library. This takes in input a text, in this case the patient history and it tokenizes it. Therefore, each word is mapped to a unique index that corresponds to a word in the tokenizer vocabulary. Of course, not all words are present in the Bert vocabulary so some words are broken into subwords. Moreover, there are some special characters that are added: [SEP] and [CLS]. The [SEP] token is added to indicate the end of a sentence and the other one is a special classification token. Bert has also two additional constraints: each sentence must be padded or truncated to a fixed length and the maximum sentence length is 512 tokens. For our task, we use the maximum possible length since there are no reasons to truncate the text and padding will not cause any issues since the dataset is quite small. The [PAD] characters are thus special tokens that indicate that those tokens are not 'expected' tokens but rather tokens added just to align the sequences to the same length. \n",
    "The encoder_plus returns two inputs that will be directly used by our model:\n",
    "- the input_ids vector that is the vector of indexes described before in which each token is mapped to a index in the Bert vocabulary\n",
    "- the attention masks vector which explicitly differentiate real tokens from [PAD] tokens.\n",
    "\n",
    "Moreover, by setting the parameter \"return_offsets_mapping\" this function also returns a vector that specify the characters start position and end position for each token. This is very useful to build the ground truth vector because it can be checked whether each token is part of an annotation in the patient history. If that is the case, it will be assigned the matching feautre to the ground truth vector entry corresponding to that token, otherwise it will be assigned a zero, the empty feauture. This procedure is done for the unique patient history texts, so the ground truth vector has shape (1000, 512) which when hot-encoded becomes (1000, 512, 144)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b323b3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:30.304451Z",
     "iopub.status.busy": "2022-12-29T21:08:30.303845Z",
     "iopub.status.idle": "2022-12-29T21:08:33.862202Z",
     "shell.execute_reply": "2022-12-29T21:08:33.861229Z"
    },
    "papermill": {
     "duration": 3.573958,
     "end_time": "2022-12-29T21:08:33.864630",
     "exception": false,
     "start_time": "2022-12-29T21:08:30.290672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not DATA_EXISTS:\n",
    "    sequences, labels, masks,  offsets_list  = [], [], [], []\n",
    "    row_ids = []\n",
    "    targets = []\n",
    "\n",
    "    for group in tqdm(train.groupby('pn_num')): #the training set is grouped by the patient number. There are 1000 unique patient numbers\n",
    "        group_df = group[1] #to extract the grouped df corresponding to each pn_num, group[0] instead returns the pn_num\n",
    "        pn_history  = group_df.iloc[0].pn_history\n",
    "        tokens = tokenizer.encode_plus(pn_history, max_length=hyperparameters['max_length'], padding='max_length', truncation=True, return_offsets_mapping=True)\n",
    "        sequence = tokens['input_ids'] #token embedding, each token is mapped to a index that represent a word or a subword in the Bert vocabulary\n",
    "        attention_mask = tokens['attention_mask'] #0 is a padded value\n",
    "\n",
    "        targets.append([])\n",
    "        row_ids.append([])\n",
    "\n",
    "        label = np.array([EMPTY_IDX for _ in range(hyperparameters['max_length'])]) \n",
    "        offsets = tokens['offset_mapping'] #vector that retuns the starting character position and the end character position of each token\n",
    "\n",
    "        label_empty = True\n",
    "        for index, row in group_df.iterrows():\n",
    "            target = row.TARGET #this is the target label representing a unique feature that has to be detected in the patient history\n",
    "            targets[-1].append(target)\n",
    "            row_ids[-1].append(row.id)\n",
    "\n",
    "            for i, (w_start, w_end) in enumerate(offsets):\n",
    "                for start, end in decode_location(row.location): \n",
    "                    if w_start < w_end and (w_start >= start) and (end >= w_end): \n",
    "                        #if the position of a token in the offset mapping vector is included between the index positions indicated by the location feature\n",
    "                        #then assign the target label of the row that is considered to the label vector entry that matches the index position of that token \n",
    "                        label[i] = target\n",
    "                        label_empty = False\n",
    "                    if w_start >= w_end:\n",
    "                        break\n",
    "        if not label_empty:\n",
    "            sequences.append(sequence)\n",
    "            masks.append(attention_mask)\n",
    "            labels.append(label)\n",
    "            offsets_list.append(offsets)\n",
    "\n",
    "    sequences = np.array(sequences).astype(np.int32) #transform the list into an array\n",
    "    masks = np.array(masks).astype(np.uint8) \n",
    "    labels = F.one_hot(torch.Tensor(np.array(labels)).long(), num_classes=N_CLASSES) #one hot encoding of labels\n",
    "    labels = np.array(labels) #to transform the tensor back to an array \n",
    "    targets_to_row_ids = [dict(zip(a,b)) for a,b in zip(targets,row_ids)]\n",
    "    np.save(open(\"masks.npy\",'wb'), masks)\n",
    "    np.save(open(\"sequences.npy\",'wb'), sequences)\n",
    "    np.save(open(\"labels.npy\",'wb'), labels)\n",
    "    np.save(open(\"targets_to_row_ids.npy\", 'wb'), targets_to_row_ids)\n",
    "    np.save(open(\"offsets_list\", 'wb'), offsets_list)\n",
    "else:\n",
    "    masks = np.load(open(DATA_PATH+\"/masks.npy\",'rb'))\n",
    "    sequences = np.load(open(DATA_PATH+\"/sequences.npy\",'rb'))\n",
    "    labels = np.load(open(DATA_PATH+\"/labels.npy\",'rb'))\n",
    "    targets_to_row_ids = np.load(open(DATA_PATH+\"/targets_to_row_ids.npy\", 'rb'),allow_pickle=True)\n",
    "    offsets_list = np.load(open(DATA_PATH+'/offsets_list', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22440be4",
   "metadata": {
    "papermill": {
     "duration": 0.011554,
     "end_time": "2022-12-29T21:08:33.888337",
     "exception": false,
     "start_time": "2022-12-29T21:08:33.876783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We create a new dataframe with only the input that is required by the Bert model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "150a47b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:33.913384Z",
     "iopub.status.busy": "2022-12-29T21:08:33.912573Z",
     "iopub.status.idle": "2022-12-29T21:08:36.574522Z",
     "shell.execute_reply": "2022-12-29T21:08:36.573560Z"
    },
    "papermill": {
     "duration": 2.67712,
     "end_time": "2022-12-29T21:08:36.577060",
     "exception": false,
     "start_time": "2022-12-29T21:08:33.899940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_bert = pd.DataFrame({'sequence': sequences.tolist(),'mask': masks.tolist(), 'label': labels.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ff739",
   "metadata": {
    "papermill": {
     "duration": 0.011633,
     "end_time": "2022-12-29T21:08:36.601172",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.589539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879b433",
   "metadata": {
    "papermill": {
     "duration": 0.011564,
     "end_time": "2022-12-29T21:08:36.625079",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.613515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If both flag variables TRAIN and VAL are set to True then the training set is splitted into train and validation sets. If only TRAIN is true then the model is trained on all the dataset to achieve the best training before the testing phase. When both the flag variables TRAIN and VAL are set to False then that indicates it is the submission phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d347c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:36.650027Z",
     "iopub.status.busy": "2022-12-29T21:08:36.649708Z",
     "iopub.status.idle": "2022-12-29T21:08:36.653490Z",
     "shell.execute_reply": "2022-12-29T21:08:36.652725Z"
    },
    "papermill": {
     "duration": 0.018727,
     "end_time": "2022-12-29T21:08:36.655436",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.636709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "VAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d64e7fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:36.680105Z",
     "iopub.status.busy": "2022-12-29T21:08:36.679845Z",
     "iopub.status.idle": "2022-12-29T21:08:36.685792Z",
     "shell.execute_reply": "2022-12-29T21:08:36.684859Z"
    },
    "papermill": {
     "duration": 0.020705,
     "end_time": "2022-12-29T21:08:36.688101",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.667396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if VAL:\n",
    "    train_bert, val_bert = train_test_split(train_bert, test_size=hyperparameters['val_size'], random_state=hyperparameters['seed'])\n",
    "    targets_to_row_ids_train, targets_to_row_ids_val = np.take(targets_to_row_ids, train_bert.index), np.take(targets_to_row_ids, val_bert.index)\n",
    "    offsets_train, offsets_val =np.take(np.array(offsets_list), train_bert.index, axis = 0), np.take(np.array(offsets_list), val_bert.index, axis= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194736c",
   "metadata": {
    "papermill": {
     "duration": 0.011869,
     "end_time": "2022-12-29T21:08:36.711600",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.699731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Dataset and Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "175c7fbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:36.736553Z",
     "iopub.status.busy": "2022-12-29T21:08:36.736277Z",
     "iopub.status.idle": "2022-12-29T21:08:36.742657Z",
     "shell.execute_reply": "2022-12-29T21:08:36.741747Z"
    },
    "papermill": {
     "duration": 0.021259,
     "end_time": "2022-12-29T21:08:36.744667",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.723408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, tokenizer, hyperparameters):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.hyperparameters = hyperparameters\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Method that returns the length of the dataset'''\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Method that processes and returns 1 datapoint at a time.'''\n",
    "        sequence = self.data.iloc[index][\"sequence\"]\n",
    "        mask = self.data.iloc[index]['mask']\n",
    "        label = self.data.iloc[index]['label']\n",
    "        return np.array(sequence), np.array(mask), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5faf288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:36.769411Z",
     "iopub.status.busy": "2022-12-29T21:08:36.768664Z",
     "iopub.status.idle": "2022-12-29T21:08:36.775258Z",
     "shell.execute_reply": "2022-12-29T21:08:36.774452Z"
    },
    "papermill": {
     "duration": 0.020923,
     "end_time": "2022-12-29T21:08:36.777205",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.756282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, hyperparameters):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(hyperparameters['model_name']) # BERT model\n",
    "        self.dropout = nn.Dropout(p=hyperparameters['dropout'])\n",
    "        self.config = config\n",
    "        self.fc1 = nn.Linear(768, N_CLASSES) \n",
    "\n",
    "    def summary(self):\n",
    "        return summary(self)\n",
    "\n",
    "    def forward(self, input_ids, attention):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention)\n",
    "        logits = self.fc1(self.dropout(outputs[0]))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bcd0fd",
   "metadata": {
    "papermill": {
     "duration": 0.011467,
     "end_time": "2022-12-29T21:08:36.800386",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.788919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89a0f7ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:36.825203Z",
     "iopub.status.busy": "2022-12-29T21:08:36.824455Z",
     "iopub.status.idle": "2022-12-29T21:08:36.835244Z",
     "shell.execute_reply": "2022-12-29T21:08:36.834446Z"
    },
    "papermill": {
     "duration": 0.025106,
     "end_time": "2022-12-29T21:08:36.837135",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.812029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion):\n",
    "    ''' \n",
    "    Function for training the model.\n",
    "        inputs : model, dataloader, optimizer, criterion\n",
    "        outputs : accuracy, precision, recall, f1_micro, train_loss\n",
    "    '''\n",
    "    model.train()\n",
    "\n",
    "    tp, tn, fp, fn, train_loss = 0, 0, 0, 0, 0\n",
    "    logits_list = []\n",
    "    for batch in tqdm(dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        loss = criterion(torch.permute(logits, (0,2,1)),torch.argmax(labels, dim = 2))\n",
    "        predicted = torch.argmax(logits,dim =  2).detach().cpu().numpy()\n",
    "        labelled = torch.argmax(labels,dim = 2).detach().cpu().numpy()\n",
    "\n",
    "        tp +=  (np.sum((predicted == labelled) & (predicted != 0)))\n",
    "        tn += (np.sum((predicted == labelled) & (predicted == 0)))\n",
    "        fp +=  (np.sum((predicted != 0) & (labelled == 0)))\n",
    "        fn += (np.sum((predicted == 0) & (labelled != 0)))\n",
    "        train_loss += (loss.item() * input_ids.size(0))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0) #clipping the gradient to avoid exploding gradients\n",
    "        optimizer.step()\n",
    "\n",
    "    accuracy = ((tp+tn)/(hyperparameters['max_length']*len(train_bert)))*100\n",
    "    try:\n",
    "        precision = (tp /(tp+fp))\n",
    "    except:\n",
    "        precision = 0.0 \n",
    "    recall = tp/(tp+fn)\n",
    "    f1_micro = tp/(tp+0.5*(fp+fn))\n",
    "    train_loss = train_loss/len(train_bert)\n",
    "    return accuracy, precision, recall, f1_micro, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98181d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:36.862213Z",
     "iopub.status.busy": "2022-12-29T21:08:36.861324Z",
     "iopub.status.idle": "2022-12-29T21:08:36.870904Z",
     "shell.execute_reply": "2022-12-29T21:08:36.870100Z"
    },
    "papermill": {
     "duration": 0.024064,
     "end_time": "2022-12-29T21:08:36.872861",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.848797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    tp, tn, fp, fn, val_loss  = 0, 0, 0, 0, 0\n",
    "    logits_list = []\n",
    "\n",
    "    for batch in tqdm(dataloader): \n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        logits = model(input_ids, attention_mask)\n",
    "\n",
    "        loss = criterion(torch.permute(logits, (0,2,1)),torch.argmax(labels, dim = 2))\n",
    "        predicted = torch.argmax(logits,dim =  2).detach().cpu().numpy()\n",
    "        labelled = torch.argmax(labels,dim = 2).detach().cpu().numpy()\n",
    "\n",
    "        tp +=  (np.sum((predicted == labelled) & (predicted != 0)))\n",
    "        tn += (np.sum((predicted == labelled) & (predicted == 0)))\n",
    "        fp +=  (np.sum((predicted != 0) & (labelled == 0)))\n",
    "        fn += (np.sum((predicted == 0) & (labelled != 0)))\n",
    "        val_loss += (loss.item() * input_ids.size(0))\n",
    "\n",
    "    try:\n",
    "        precision = (tp /(tp+fp))\n",
    "    except:\n",
    "        precision = 0.0 \n",
    "    recall = tp/(tp+fn)\n",
    "    f1_micro = tp/(tp+0.5*(fp+fn))\n",
    "    val_loss = val_loss/len(val_bert)\n",
    "    return accuracy, precision, recall, f1_micro, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca202c",
   "metadata": {
    "papermill": {
     "duration": 0.011486,
     "end_time": "2022-12-29T21:08:36.896331",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.884845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286400bd",
   "metadata": {
    "papermill": {
     "duration": 0.011463,
     "end_time": "2022-12-29T21:08:36.919502",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.908039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To create a dataframe to test the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5f71c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:36.944232Z",
     "iopub.status.busy": "2022-12-29T21:08:36.943488Z",
     "iopub.status.idle": "2022-12-29T21:08:36.949606Z",
     "shell.execute_reply": "2022-12-29T21:08:36.948798Z"
    },
    "papermill": {
     "duration": 0.020384,
     "end_time": "2022-12-29T21:08:36.951537",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.931153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_old = pd.DataFrame([['','','', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], columns = ['batch_size', 'lr', 'epochs', 'train_acc', 'val_acc', 'train_loss', 'val_loss', 'train_prec', 'val_prec', 'train_rec', 'val_rec', 'train_f1', 'val_f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d320bb",
   "metadata": {
    "papermill": {
     "duration": 0.011578,
     "end_time": "2022-12-29T21:08:36.974813",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.963235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The nested for-loops have been created just to test all possible combinations of hyperparameters. The best model is then saved. When the final training with all data is needed to be run then the loop can be commented out and the batch_size, epochs and lr set to the \"right\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5d6f8dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:36.999309Z",
     "iopub.status.busy": "2022-12-29T21:08:36.998998Z",
     "iopub.status.idle": "2022-12-29T21:08:46.523628Z",
     "shell.execute_reply": "2022-12-29T21:08:46.522618Z"
    },
    "papermill": {
     "duration": 9.539286,
     "end_time": "2022-12-29T21:08:46.525846",
     "exception": false,
     "start_time": "2022-12-29T21:08:36.986560",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc1): Linear(in_features=768, out_features=144, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model = CustomModel(hyperparameters).to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b75ba7a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:46.553124Z",
     "iopub.status.busy": "2022-12-29T21:08:46.552826Z",
     "iopub.status.idle": "2022-12-29T21:08:49.983233Z",
     "shell.execute_reply": "2022-12-29T21:08:49.982323Z"
    },
    "papermill": {
     "duration": 3.446796,
     "end_time": "2022-12-29T21:08:49.985790",
     "exception": false,
     "start_time": "2022-12-29T21:08:46.538994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    \n",
    "    for comb in range(3):\n",
    "        for comb_2 in range(3):\n",
    "            for size in range(2):\n",
    "                \n",
    "                training_data = CustomDataset(train_bert, tokenizer, hyperparameters)\n",
    "                train_dataloader = DataLoader(training_data, batch_size=hyperparameters['batch_size'][size], shuffle=True, worker_init_fn=seed_worker,generator=g)\n",
    "\n",
    "                # Define the loss function\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "                # Define the optimizer\n",
    "                optimizer = optim.AdamW(model.parameters(), lr=hyperparameters['lr'][comb])\n",
    "\n",
    "\n",
    "                if VAL:\n",
    "                    val_data = CustomDataset(val_bert, tokenizer, hyperparameters)\n",
    "                    val_dataloader = DataLoader(val_data, batch_size=hyperparameters['batch_size'][size], shuffle=False, worker_init_fn=seed_worker,generator=g)\n",
    "                    val_loss_min = np.Inf\n",
    "                    best_loss = np.inf\n",
    "                    \n",
    "                since = time.time()\n",
    "                epochs = hyperparameters['epochs'][comb_2]\n",
    "                train_acc, val_acc, train_loss, val_loss, train_prec, val_prec, train_rec, val_rec, train_f1, val_f1 = list(), list(), list(), list(), list(), list(), list(), list(), list(), list()\n",
    "\n",
    "                for i in range(epochs):\n",
    "\n",
    "                    print(\"Epoch: {}/{}\".format(i + 1, epochs))\n",
    "                    #TRAIN THE MODEL \n",
    "                    t_acc, t_prec, t_rec, t_f1, t_loss = train_model(model, train_dataloader, optimizer, criterion) # t_prec, t_rec, t_f1\n",
    "                    train_acc.append(t_acc)\n",
    "                    train_loss.append(t_loss)\n",
    "                    train_prec.append(float(t_prec))\n",
    "                    train_rec.append(float(t_rec))\n",
    "                    train_f1.append(float(t_f1))\n",
    "                    print(f\"TRAINING. Loss: {t_loss:.2f};, Accuracy: {t_acc:.2f}; Precision: {t_prec:.2f}; Recall: {t_rec:.2f}; Micro-F1 score: {t_f1:.2f}\")\n",
    "                    #VALIDATE THE MODEL\n",
    "                    if VAL:\n",
    "                        v_acc, v_prec, v_rec, v_f1, v_loss = eval_model(model, val_dataloader, criterion)\n",
    "                        val_acc.append(v_acc)\n",
    "                        val_loss.append(v_loss)\n",
    "                        val_prec.append(float(v_prec))\n",
    "                        val_rec.append(float(v_rec))\n",
    "                        val_f1.append(float(v_f1))\n",
    "                        print(f\"VALIDATION. Loss: {v_loss:.2f};, Accuracy: {v_acc:.2f}; Precision: {v_prec:.2f}; Recall: {v_rec:.2f}; Micro-F1 score: {v_f1:.2f}\")\n",
    "\n",
    "                        if v_loss < best_loss: #to save the model with best validation loss\n",
    "                            best_loss = v_loss\n",
    "                            torch.save(model.state_dict(), \"nbme_bert_v2.pth\")\n",
    "\n",
    "                time_elapsed = time.time() - since\n",
    "                print('Training completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "                if VAL:\n",
    "                    \n",
    "                    #save the results to a dataframe\n",
    "                    df = pd.DataFrame([[str(hyperparameters['batch_size'][size]), str(hyperparameters['lr'][comb]), str(hyperparameters['epochs'][comb_2]), train_acc[-1], val_acc[-1], train_loss[-1], val_loss[-1], train_prec[-1], val_prec[-1], train_rec[-1], val_rec[-1], train_f1[-1], val_f1[-1]]], columns = ['batch_size', 'lr', 'epochs', 'train_acc', 'val_acc', 'train_loss', 'val_loss', 'train_prec', 'val_prec', 'train_rec', 'val_rec', 'train_f1', 'val_f1'])\n",
    "                    df_old = pd.concat([df_old, df], join = 'inner')\n",
    "                    df_old = df_old.sort_values(by = 'val_f1',ascending=False)\n",
    "                    df_old.to_csv('df.csv')\n",
    "                    \n",
    "                    # Plot the results\n",
    "                    plt.plot(train_loss, \"-o\", label='Training loss')\n",
    "                    plt.plot(val_loss, \"-o\", label='Validation loss')\n",
    "                    plt.title('Training and validation loss')\n",
    "                    plt.xlabel('epochs')\n",
    "                    plt.ylabel('loss')\n",
    "                    plt.legend()\n",
    "                    plt.savefig(f'loss.png', dpi=300)\n",
    "                    plt.figure()\n",
    "\n",
    "                    plt.plot(train_acc, \"-o\", label='Training accuracy')\n",
    "                    plt.plot(val_acc, \"-o\", label='Validation accuracy')\n",
    "                    plt.title('Training and validation accuracy')\n",
    "                    plt.xlabel('epochs')\n",
    "                    plt.ylabel('accuracy')\n",
    "                    plt.legend()\n",
    "                    plt.savefig(f'acc.png', dpi=300)\n",
    "                    plt.figure()\n",
    "\n",
    "                    plt.plot(train_prec, \"-o\", label='Training precision')\n",
    "                    plt.plot(val_prec, \"-o\", label='Validation precision')\n",
    "                    plt.title('Training and validation precision')\n",
    "                    plt.xlabel('epochs')\n",
    "                    plt.ylabel('precision')\n",
    "                    plt.legend()\n",
    "                    plt.savefig(f'prec.png', dpi=300)\n",
    "                    plt.figure()\n",
    "\n",
    "                    plt.plot(train_rec, \"-o\", label='Training recall')\n",
    "                    plt.plot(val_rec, \"-o\", label='Validation recall')\n",
    "                    plt.title('Training and validation recall')\n",
    "                    plt.xlabel('epochs')\n",
    "                    plt.ylabel('recall')\n",
    "                    plt.legend()\n",
    "                    plt.savefig(f'recall.png', dpi=300)\n",
    "                    plt.figure()\n",
    "\n",
    "                    plt.plot(train_f1, \"-o\", label='Training F1-Score')\n",
    "                    plt.plot(val_f1, \"-o\", label='Validation F1-Score')\n",
    "                    plt.title('Training and validation F1-Score')\n",
    "                    plt.xlabel('epochs')\n",
    "                    plt.ylabel('f1-score')\n",
    "                    plt.legend()\n",
    "                    plt.savefig(f'f1score.png', dpi=300)\n",
    "                    plt.figure()\n",
    "                    \n",
    "                else: #if training on the all dataset without validating\n",
    "                    torch.save(model.state_dict(), \"new_model.pth\")\n",
    "else: #testing phase\n",
    "    model.load_state_dict(torch.load(DATA_PATH + \"/new_model.pth\", map_location = device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f135b5e2",
   "metadata": {
    "papermill": {
     "duration": 0.01207,
     "end_time": "2022-12-29T21:08:50.010480",
     "exception": false,
     "start_time": "2022-12-29T21:08:49.998410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a0164",
   "metadata": {
    "papermill": {
     "duration": 0.011947,
     "end_time": "2022-12-29T21:08:50.034575",
     "exception": false,
     "start_time": "2022-12-29T21:08:50.022628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Creating the ids vector, the attention mask vector and the offset mapping vector for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b6d5cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:50.060891Z",
     "iopub.status.busy": "2022-12-29T21:08:50.060585Z",
     "iopub.status.idle": "2022-12-29T21:08:50.115452Z",
     "shell.execute_reply": "2022-12-29T21:08:50.114626Z"
    },
    "papermill": {
     "duration": 0.070202,
     "end_time": "2022-12-29T21:08:50.117603",
     "exception": false,
     "start_time": "2022-12-29T21:08:50.047401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0761969a95de4bb6b9f868e796c87ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sequences, test_masks, test_offsets = [], [],[]\n",
    "row_ids = []\n",
    "targets = []\n",
    "\n",
    "for g1 in tqdm(test.groupby('pn_num')):\n",
    "    gdf = g1[1]\n",
    "    pn_history  = gdf.iloc[0].pn_history\n",
    "    targets.append([])\n",
    "    row_ids.append([])\n",
    "\n",
    "    test_tokens = tokenizer.encode_plus(pn_history, max_length=hyperparameters['max_length'], padding='max_length',truncation=True, return_offsets_mapping=True)\n",
    "    test_sequence = test_tokens['input_ids']\n",
    "    test_attention_mask = test_tokens['attention_mask'] \n",
    "\n",
    "    # BUILD THE TARGET ARRAY\n",
    "    offset = test_tokens['offset_mapping']\n",
    "    for index, row in gdf.iterrows():\n",
    "        targets[-1].append(row.TARGET)\n",
    "        row_ids[-1].append(row.id)\n",
    "\n",
    "    test_sequences.append(test_sequence)\n",
    "    test_masks.append(test_attention_mask)\n",
    "    test_offsets.append(offset)\n",
    "\n",
    "test_sequences = np.array(test_sequences).astype(np.int32)\n",
    "test_masks = np.array(test_masks).astype(np.uint8)\n",
    "targets_to_row_ids_test = [dict(zip(a,b)) for a,b in zip(targets,row_ids)]\n",
    "test_bert = pd.DataFrame({'sequence': test_sequences.tolist(),'mask': test_masks.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8175e",
   "metadata": {
    "papermill": {
     "duration": 0.012464,
     "end_time": "2022-12-29T21:08:50.142700",
     "exception": false,
     "start_time": "2022-12-29T21:08:50.130236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### The SubmissionDataset class is similar to the CustomDataset class except that it does not return any ground truth in the \\__geitem\\__ method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8a14671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:50.168815Z",
     "iopub.status.busy": "2022-12-29T21:08:50.168519Z",
     "iopub.status.idle": "2022-12-29T21:08:50.174401Z",
     "shell.execute_reply": "2022-12-29T21:08:50.173388Z"
    },
    "papermill": {
     "duration": 0.021339,
     "end_time": "2022-12-29T21:08:50.176690",
     "exception": false,
     "start_time": "2022-12-29T21:08:50.155351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SubmissionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, config):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''Function that processes and returns 1 datapoint at a time.'''\n",
    "        sequence = self.data.iloc[index][\"sequence\"]\n",
    "        mask = self.data.iloc[index]['mask']\n",
    "        return np.array(sequence), np.array(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7863150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:50.202442Z",
     "iopub.status.busy": "2022-12-29T21:08:50.202155Z",
     "iopub.status.idle": "2022-12-29T21:08:50.208040Z",
     "shell.execute_reply": "2022-12-29T21:08:50.207210Z"
    },
    "papermill": {
     "duration": 0.021254,
     "end_time": "2022-12-29T21:08:50.210020",
     "exception": false,
     "start_time": "2022-12-29T21:08:50.188766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_data = SubmissionDataset(test_bert, tokenizer, hyperparameters)\n",
    "submission_dataloader = DataLoader(submission_data, batch_size=4, shuffle=False, worker_init_fn=seed_worker,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55772040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:50.235373Z",
     "iopub.status.busy": "2022-12-29T21:08:50.235097Z",
     "iopub.status.idle": "2022-12-29T21:08:51.315104Z",
     "shell.execute_reply": "2022-12-29T21:08:51.314214Z"
    },
    "papermill": {
     "duration": 1.094952,
     "end_time": "2022-12-29T21:08:51.317048",
     "exception": false,
     "start_time": "2022-12-29T21:08:50.222096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0379ed13c04749258cf3bd67d80b460a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "logits_list = []\n",
    "val_loss = 0\n",
    "\n",
    "for batch in tqdm(submission_dataloader): \n",
    "    input_ids = batch[0].to(device)\n",
    "    attention_mask = batch[1].to(device)\n",
    "    logits = model(input_ids, attention_mask)\n",
    "    logits_list.append(logits.detach().cpu().numpy())\n",
    "\n",
    "logits = np.concatenate(logits_list, axis = 0)\n",
    "preds = np.argmax((logits), -1) #to transform it from one-hot encoding predictions to numerical predicitons from 0 to 143"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4631dcc",
   "metadata": {
    "papermill": {
     "duration": 0.012094,
     "end_time": "2022-12-29T21:08:51.341897",
     "exception": false,
     "start_time": "2022-12-29T21:08:51.329803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The predictions vector output of the model has the first dimension equal to the number of unique patient history in the test set and the second dimension, after applying np.argmax(),  equals the number of unique features, 144. So the translate() function is applied in order to take the prediction vectors and to output the corresponding location of every target feature in the test set. Every row is a different feature to be searched and many rows share the same patient history text. Since this model outputs the predictions of different features all concatenated toghether in the same vector, the translate() function splits the prediction vector into the format required by the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fff1e851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T21:08:51.368039Z",
     "iopub.status.busy": "2022-12-29T21:08:51.367757Z",
     "iopub.status.idle": "2022-12-29T21:08:51.382698Z",
     "shell.execute_reply": "2022-12-29T21:08:51.381696Z"
    },
    "papermill": {
     "duration": 0.030453,
     "end_time": "2022-12-29T21:08:51.384782",
     "exception": false,
     "start_time": "2022-12-29T21:08:51.354329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>696 724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>668 693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>203 217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>70 91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id location\n",
       "0  00016_000  696 724\n",
       "1  00016_001  668 693\n",
       "2  00016_002  203 217\n",
       "3  00016_003    70 91\n",
       "4  00016_004         "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = translate(preds.reshape(len(preds),512),targets_to_row_ids_test,test_offsets).sort_values('id')\n",
    "\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.035232,
   "end_time": "2022-12-29T21:08:53.771206",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-29T21:08:17.735974",
   "version": "2.3.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0379ed13c04749258cf3bd67d80b460a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e72dc6229a9440d2b4fc2b209747fe29",
        "IPY_MODEL_1cd79da7a4f740dd8aae0545d5deb8bb",
        "IPY_MODEL_c7bd81e003fe442a86943bb585ac1f90"
       ],
       "layout": "IPY_MODEL_86e485fcd3c24bd09ea09f962ed917d5"
      }
     },
     "0761969a95de4bb6b9f868e796c87ba0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bee7e6ee4d1240acbc536396c00ca11c",
        "IPY_MODEL_7a735058db00416abd179c8399745630",
        "IPY_MODEL_76d3506de35f41f89eeca47cc7e247b8"
       ],
       "layout": "IPY_MODEL_276fa5059555496fb4e752ac1930a6f9"
      }
     },
     "09a58a493d204d6f8b5c8e2a8c962e94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0ddd1ede3df34053bd952fedc219b973": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1cd79da7a4f740dd8aae0545d5deb8bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_215fa040d3fc47e9b7035a0768b17c16",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_09a58a493d204d6f8b5c8e2a8c962e94",
       "value": 1
      }
     },
     "215fa040d3fc47e9b7035a0768b17c16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "276fa5059555496fb4e752ac1930a6f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "449e7d83310c4094a4efcf2109b49bb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ac62da365ed46cab3eae35990e2c960": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fe6a638f6334925afc1b83a710af782": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "76d3506de35f41f89eeca47cc7e247b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_96d0c4d6963d45428d1597e8696ef390",
       "placeholder": "",
       "style": "IPY_MODEL_b94c28a5b48a49658fe74469d481508e",
       "value": " 1/1 [00:00&lt;00:00, 27.58it/s]"
      }
     },
     "77b2b4f8ca3c4f8dabdf2af5d282502e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7a735058db00416abd179c8399745630": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d112320ec7e64275a312ded6f8f2482a",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_77b2b4f8ca3c4f8dabdf2af5d282502e",
       "value": 1
      }
     },
     "86e485fcd3c24bd09ea09f962ed917d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96d0c4d6963d45428d1597e8696ef390": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98d88f488f1d4c77914b3584c6f879bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b30d1a32e6ec4654af436c4b229623ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b94c28a5b48a49658fe74469d481508e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bee7e6ee4d1240acbc536396c00ca11c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b30d1a32e6ec4654af436c4b229623ba",
       "placeholder": "",
       "style": "IPY_MODEL_98d88f488f1d4c77914b3584c6f879bb",
       "value": "100%"
      }
     },
     "c7bd81e003fe442a86943bb585ac1f90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_449e7d83310c4094a4efcf2109b49bb1",
       "placeholder": "",
       "style": "IPY_MODEL_0ddd1ede3df34053bd952fedc219b973",
       "value": " 1/1 [00:01&lt;00:00,  1.07s/it]"
      }
     },
     "d112320ec7e64275a312ded6f8f2482a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e72dc6229a9440d2b4fc2b209747fe29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ac62da365ed46cab3eae35990e2c960",
       "placeholder": "",
       "style": "IPY_MODEL_4fe6a638f6334925afc1b83a710af782",
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
